# Apache Airflow 3.0.3 Configuration File

[database]
sql_alchemy_conn = ${AIRFLOW_DB_CONNECTION}
sql_alchemy_pool_enabled = True
sql_alchemy_pool_size = 5

[core]
# Core Airflow settings
dags_folder = C:\temp\airflow\dags
plugins_folder = C:\temp\airflow\plugins
base_log_folder = C:\temp\airflow\logs
executor = LocalExecutor
load_examples = False
load_default_connections = False
parallelism = 32
max_active_tasks_per_dag = 16
max_active_runs_per_dag = 1
dagbag_import_timeout = 30
dag_file_processor_timeout = 50

# Security enhancements (new in 3.0)
enable_xcom_pickling = False
sensitive_var_conn_names = password,secret,token,key
hide_sensitive_var_conn_fields = True

[scheduler]  
# Scheduler configuration
scheduler_heartbeat_sec = 5
dag_dir_list_interval = 300
min_file_process_interval = 30
catchup_by_default = False
max_threads = 2

# Enhanced scheduling (new features)
scheduler_idle_sleep_time = 1
max_tis_per_query = 512
use_job_schedule = True

[webserver]
# Web server configuration  
base_url = http://localhost:8080
web_server_host = 0.0.0.0
web_server_port = 8080
workers = 4
worker_class = sync
worker_timeout = 120
expose_config = True
dag_default_view = graph
dag_orientation = LR

# Security features (enhanced in 3.0)
csrf_enabled = True
session_cookie_secure = True
session_cookie_httponly = True
secret_key = your-secret-key-here

# UI improvements
page_size = 100
hide_paused_dags_by_default = False
auto_refresh_interval = 30

[smtp]
# Email configuration
smtp_host = localhost  
smtp_starttls = True
smtp_ssl = False
smtp_port = 587
smtp_mail_from = airflow@company.com

[api]
# REST API configuration
auth_backends = airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session
maximum_page_limit = 100
fallback_page_limit = 100

# Enhanced API features (new in 3.0)
enable_experimental_api = False
api_client_retry_configuration = True

[logging]
# Logging configuration
base_log_folder = C:\temp\airflow\logs
remote_logging = False
logging_level = INFO
colored_console_log = True
log_format = [%%(asctime)s] {%%(filename)s:%%(lineno)d} %%(levelname)s - %%(message)s
simple_log_format = %%(asctime)s %%(levelname)s - %%(message)s

# Enhanced logging (new features)
log_processor_filename_template = {{ filename }}.log
log_filename_template = {{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log

[metrics]
# Metrics and monitoring (enhanced in 3.0)
statsd_on = False
statsd_host = localhost
statsd_port = 8125
statsd_prefix = airflow

[secrets]
# Secrets management (new in 3.0)
backend = airflow.secrets.local_filesystem.LocalFilesystemBackend
backend_kwargs = {"variables_file_path": "variables.json", "connections_file_path": "connections.json"}

[operators]
# Default operator settings
default_owner = airflow
default_cpus = 1
default_ram = 512
default_disk = 512

[celery]
# Celery configuration (if using CeleryExecutor)
worker_concurrency = 16
broker_url = redis://localhost:6379/0
result_backend = db+${AIRFLOW_DB_CONNECTION}
flower_host = 0.0.0.0
flower_port = 5555

[kubernetes]
# Kubernetes configuration (if using KubernetesExecutor)
namespace = airflow
worker_container_repository = apache/airflow
worker_container_tag = 3.0.3
delete_worker_pods = True